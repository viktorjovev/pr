{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework2_186068_Jovev_Viktor.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zcMdO8riG4o_",
        "kMncOLKQG7v5",
        "SMH5JRYAY6OI",
        "Uy3CJ4Aov7TW",
        "HSlV0qcfxeuO",
        "BcnbI5zYHBrB",
        "KVaA_gAkb0yQ",
        "HZIEUCmEcZ-F",
        "su2YL5jZvXH4",
        "nLpY7EvAHLqx",
        "4CGhilWt7bM4",
        "sfN7nZa87jBj",
        "cOifnhKnUokX",
        "p29OgL3HHQ7X",
        "sCVPDN-ncIIa",
        "CSEPaUCcdMK8",
        "xymMbiEqgnXL",
        "LyLdJ1B9HUpo",
        "mG0_ZyCP1-r9",
        "wgK_iJW04Drw",
        "s0EJLSUH5-kP"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMyPCzXe5oqou5sjjrFjcNv"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcMdO8riG4o_"
      },
      "source": [
        "#Модули\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1xUnhB8G47p"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate, train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from scipy.io import arff\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMncOLKQG7v5"
      },
      "source": [
        "# A) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMH5JRYAY6OI"
      },
      "source": [
        "## Генерирање на тренинг/тест множество\n",
        "Нема точки кои што се над/под кривата, сите точки лежат на кривата. \n",
        "Поради тоа, дадов threshold 0.5, така што  \n",
        "**Ако y>0.5 тогаш класифицирај како 1**  \n",
        "**Ако y<=0.5 тогаш класифицирај како 0**\n",
        "\n",
        "2 линија - листа од x координати со вредности меѓу 0 и 1  \n",
        "3 линија - листа каде што ги енкодираме вредностите на y во 0 или 1 во зависност од исполнетоста на условот"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ks74jcCHZBt"
      },
      "source": [
        "def generate_dataset_A(train_size, test_size):\n",
        "  x_train = np.random.ranf(train_size)\n",
        "  y_train = np.where((np.sin(6*x_train)/6) + 0.6>0.5, 1, 0)\n",
        "\n",
        "  x_test = np.random.ranf(test_size)\n",
        "  y_test = np.where((np.sin(6*x_test)/6) + 0.6>0.5, 1, 0)\n",
        "  return x_train, x_test, y_train, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q46w6WnsbUyA"
      },
      "source": [
        "x_train_100, x_test_50, y_train_100, y_test_50 = generate_dataset_A(100,50)\n",
        "x_train_1000, x_test_300, y_train_1000, y_test_300 = generate_dataset_A(1000,300)\n",
        "x_train_10000, x_test_3000, y_train_10000, y_test_3000 = generate_dataset_A(10000,3000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy3CJ4Aov7TW"
      },
      "source": [
        "## Модел со KNN класификација\n",
        "\n",
        "Со ова парче код испробуваме 3 вредности за neighbors при креирање на моделот KNN класификација и за истото извршуваме тестирање со тоа што се печатат мерките accuracy, recall, precision и f1 score.\n",
        "\n",
        "Согледуваме дека сегде е 1.0 при предвидувањето, бидејќи е hard coded искодирано, односно самите го поставивме threshold-от, со тоа му олеснуваме многу на моделот да предвиди точно."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kx2rXofi0ya",
        "outputId": "497d3800-401c-420e-ecc8-ba21a4c8055c"
      },
      "source": [
        "for k_neighbors in [1,3,7]:\n",
        "  model = KNeighborsClassifier(n_neighbors=k_neighbors)\n",
        "\n",
        "  model.fit(x_train_100.reshape(-1,1),y_train_100.ravel())\n",
        "  y_pred_50 = model.predict(x_test_50.reshape(-1,1))\n",
        "  \n",
        "  model.fit(x_train_1000.reshape(-1,1),y_train_1000.ravel())\n",
        "  y_pred_300 = model.predict(x_test_300.reshape(-1,1))\n",
        "\n",
        "  model.fit(x_train_10000.reshape(-1,1),y_train_10000.ravel())\n",
        "  y_pred_3000 = model.predict(x_test_3000.reshape(-1,1))\n",
        "\n",
        "  print(\"K =\",k_neighbors)\n",
        "  print(classification_report(y_test_50,y_pred_50))\n",
        "  print(classification_report(y_test_300,y_pred_300))\n",
        "  print(classification_report(y_test_3000,y_pred_3000))\n",
        "  print(\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K = 1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        11\n",
            "           1       1.00      1.00      1.00        39\n",
            "\n",
            "    accuracy                           1.00        50\n",
            "   macro avg       1.00      1.00      1.00        50\n",
            "weighted avg       1.00      1.00      1.00        50\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        74\n",
            "           1       1.00      1.00      1.00       226\n",
            "\n",
            "    accuracy                           1.00       300\n",
            "   macro avg       1.00      1.00      1.00       300\n",
            "weighted avg       1.00      1.00      1.00       300\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       941\n",
            "           1       1.00      1.00      1.00      2059\n",
            "\n",
            "    accuracy                           1.00      3000\n",
            "   macro avg       1.00      1.00      1.00      3000\n",
            "weighted avg       1.00      1.00      1.00      3000\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "K = 3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        11\n",
            "           1       1.00      1.00      1.00        39\n",
            "\n",
            "    accuracy                           1.00        50\n",
            "   macro avg       1.00      1.00      1.00        50\n",
            "weighted avg       1.00      1.00      1.00        50\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99        74\n",
            "           1       1.00      1.00      1.00       226\n",
            "\n",
            "    accuracy                           1.00       300\n",
            "   macro avg       1.00      0.99      1.00       300\n",
            "weighted avg       1.00      1.00      1.00       300\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       941\n",
            "           1       1.00      1.00      1.00      2059\n",
            "\n",
            "    accuracy                           1.00      3000\n",
            "   macro avg       1.00      1.00      1.00      3000\n",
            "weighted avg       1.00      1.00      1.00      3000\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "K = 7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96        11\n",
            "           1       1.00      0.97      0.99        39\n",
            "\n",
            "    accuracy                           0.98        50\n",
            "   macro avg       0.96      0.99      0.97        50\n",
            "weighted avg       0.98      0.98      0.98        50\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99        74\n",
            "           1       0.99      1.00      1.00       226\n",
            "\n",
            "    accuracy                           0.99       300\n",
            "   macro avg       1.00      0.99      0.99       300\n",
            "weighted avg       0.99      0.99      0.99       300\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       941\n",
            "           1       1.00      1.00      1.00      2059\n",
            "\n",
            "    accuracy                           1.00      3000\n",
            "   macro avg       1.00      1.00      1.00      3000\n",
            "weighted avg       1.00      1.00      1.00      3000\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSlV0qcfxeuO"
      },
      "source": [
        "## Модел со Decision Tree \n",
        "\n",
        "Ги менуваме вредностите на криетериумот при поделба, односно Џини индекс или ентропија и на максималната длабочина на дрвото при поделба, всушност пробуваме со длабочина од 10 и од 100.  \n",
        "Pattern-от лесно е најден од дрвото на одлука, затоа и имаме максимален број на предвидувања во сите примероци."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91FsvAgMxhxC",
        "outputId": "80b3395a-f4e8-4020-958e-db1858a6625e"
      },
      "source": [
        "for criteria in ['gini','entropy']:\n",
        "  for depth in [10,100]:\n",
        "    model = DecisionTreeClassifier(criterion=criteria, max_depth=depth,random_state=42)\n",
        "    \n",
        "    model.fit(x_train_100.reshape(-1,1),y_train_100.ravel())\n",
        "    y_pred_50 = model.predict(x_test_50.reshape(-1,1))\n",
        "\n",
        "    model.fit(x_train_1000.reshape(-1,1),y_train_1000.ravel())\n",
        "    y_pred_300 = model.predict(x_test_300.reshape(-1,1))\n",
        "\n",
        "    model.fit(x_train_10000.reshape(-1,1),y_train_10000.ravel())\n",
        "    y_pred_3000 = model.predict(x_test_3000.reshape(-1,1))\n",
        "\n",
        "    print(\"CRITERION=\",criteria,\"\\tMAX DEPTH=\",depth)\n",
        "    print(classification_report(y_test_50,y_pred_50))\n",
        "    print(classification_report(y_test_300,y_pred_300))\n",
        "    print(classification_report(y_test_3000,y_pred_3000))\n",
        "    print(\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CRITERION= gini \tMAX DEPTH= 10\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        11\n",
            "           1       1.00      1.00      1.00        39\n",
            "\n",
            "    accuracy                           1.00        50\n",
            "   macro avg       1.00      1.00      1.00        50\n",
            "weighted avg       1.00      1.00      1.00        50\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        74\n",
            "           1       1.00      1.00      1.00       226\n",
            "\n",
            "    accuracy                           1.00       300\n",
            "   macro avg       1.00      1.00      1.00       300\n",
            "weighted avg       1.00      1.00      1.00       300\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       941\n",
            "           1       1.00      1.00      1.00      2059\n",
            "\n",
            "    accuracy                           1.00      3000\n",
            "   macro avg       1.00      1.00      1.00      3000\n",
            "weighted avg       1.00      1.00      1.00      3000\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CRITERION= gini \tMAX DEPTH= 100\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        11\n",
            "           1       1.00      1.00      1.00        39\n",
            "\n",
            "    accuracy                           1.00        50\n",
            "   macro avg       1.00      1.00      1.00        50\n",
            "weighted avg       1.00      1.00      1.00        50\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        74\n",
            "           1       1.00      1.00      1.00       226\n",
            "\n",
            "    accuracy                           1.00       300\n",
            "   macro avg       1.00      1.00      1.00       300\n",
            "weighted avg       1.00      1.00      1.00       300\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       941\n",
            "           1       1.00      1.00      1.00      2059\n",
            "\n",
            "    accuracy                           1.00      3000\n",
            "   macro avg       1.00      1.00      1.00      3000\n",
            "weighted avg       1.00      1.00      1.00      3000\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CRITERION= entropy \tMAX DEPTH= 10\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        11\n",
            "           1       1.00      1.00      1.00        39\n",
            "\n",
            "    accuracy                           1.00        50\n",
            "   macro avg       1.00      1.00      1.00        50\n",
            "weighted avg       1.00      1.00      1.00        50\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        74\n",
            "           1       1.00      1.00      1.00       226\n",
            "\n",
            "    accuracy                           1.00       300\n",
            "   macro avg       1.00      1.00      1.00       300\n",
            "weighted avg       1.00      1.00      1.00       300\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       941\n",
            "           1       1.00      1.00      1.00      2059\n",
            "\n",
            "    accuracy                           1.00      3000\n",
            "   macro avg       1.00      1.00      1.00      3000\n",
            "weighted avg       1.00      1.00      1.00      3000\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CRITERION= entropy \tMAX DEPTH= 100\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        11\n",
            "           1       1.00      1.00      1.00        39\n",
            "\n",
            "    accuracy                           1.00        50\n",
            "   macro avg       1.00      1.00      1.00        50\n",
            "weighted avg       1.00      1.00      1.00        50\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        74\n",
            "           1       1.00      1.00      1.00       226\n",
            "\n",
            "    accuracy                           1.00       300\n",
            "   macro avg       1.00      1.00      1.00       300\n",
            "weighted avg       1.00      1.00      1.00       300\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       941\n",
            "           1       1.00      1.00      1.00      2059\n",
            "\n",
            "    accuracy                           1.00      3000\n",
            "   macro avg       1.00      1.00      1.00      3000\n",
            "weighted avg       1.00      1.00      1.00      3000\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcnbI5zYHBrB"
      },
      "source": [
        "# Б)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVaA_gAkb0yQ"
      },
      "source": [
        "## Генерирање на тренинг/тест множество\n",
        "\n",
        "На почетокот [од 2 до 4 линија] генерираме random случајни и y координати со опсег од 0 до 1.  \n",
        "После за секоја точка гледаме дали припаѓа во опсезите за црн или бел квадрат.  \n",
        "Тоа го правиме со помош на координатниот систем. Пример:  \n",
        "\n",
        "Ако имаме генерирано точка (0.42, 0.77), и сега ги проверуваме вредностите за границите кои се дефинирани за дали  \n",
        "x = 0.42 се наоѓа меѓу 0.25 и 0.5, уствари тоа е втората колона  \n",
        "y = 0.77 се наоѓа меѓу 0.75 и 1.0, всушност тоа е првиот ред од шаховската табла.  \n",
        "\n",
        "Значи гледаме на полето во шаховската табла b4 и тоа е црно поле."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGLY6UUMNMBK"
      },
      "source": [
        "def generate_dataset_B(train_size, test_size):\n",
        "  x_cord = np.random.ranf(train_size)\n",
        "  y_cord = np.random.ranf(train_size)\n",
        "  x_train = [list(point) for point in zip(x_cord,y_cord)]\n",
        "  y_train = list()\n",
        "\n",
        "  for point in x_train:\n",
        "    if (0<point[0]<0.25 and 0<point[1]<0.25) or (0.5<point[0]<0.75 and 0<point[1]<0.25) or (0.25<point[0]<0.50 and 0.25<point[1]<0.50) or (0.75<point[0]<1 and 0.25<point[1]<0.50) or (0<point[0]<0.25 and 0.50<point[1]<0.75) or (0.50<point[0]<0.75 and 0.50<point[1]<0.75) or (0<point[0]<0.25 and 0.50<point[1]<0.75) or (0.25<point[0]<0.5 and 0.75<point[1]<1.0) or (0.75<point[0]<1.0 and 0.75<point[1]<1.0):\n",
        "      y_train.append(1)\n",
        "    else:\n",
        "      y_train.append(0)\n",
        "\n",
        "  x_cord = np.random.ranf(test_size)\n",
        "  y_cord = np.random.ranf(test_size)\n",
        "\n",
        "  x_test = [list(point) for point in zip(x_cord,y_cord)]\n",
        "  y_test = list()\n",
        "\n",
        "  for point in x_test:\n",
        "    if (0<point[0]<0.25 and 0<point[1]<0.25) or (0.5<point[0]<0.75 and 0<point[1]<0.25) or (0.25<point[0]<0.50 and 0.25<point[1]<0.50) or (0.75<point[0]<1 and 0.25<point[1]<0.50) or (0<point[0]<0.25 and 0.50<point[1]<0.75) or (0.50<point[0]<0.75 and 0.50<point[1]<0.75) or (0<point[0]<0.25 and 0.50<point[1]<0.75) or (0.25<point[0]<0.5 and 0.75<point[1]<1.0) or (0.75<point[0]<1.0 and 0.75<point[1]<1.0):\n",
        "      y_test.append(1)\n",
        "    else:\n",
        "      y_test.append(0)\n",
        "\n",
        "  return x_train, x_test, y_train, y_test\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYLk81C3uHB2"
      },
      "source": [
        "x_train_100, x_test_50, y_train_100, y_test_50 = generate_dataset_B(100,50)\n",
        "x_train_1000, x_test_300, y_train_1000, y_test_300 = generate_dataset_B(1000,300)\n",
        "x_train_10000, x_test_3000, y_train_10000, y_test_3000 = generate_dataset_B(10000,3000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZIEUCmEcZ-F"
      },
      "source": [
        "## Модел со KNN класификација\n",
        "\n",
        "Овде можеме да видиме без разлика на параметарот за n соседи, не го менува резултатот во третото множество каде што тренирачкото се состои од 10000 примероци. Што значи овде гледаме дека колку повеќе примероци има за тренинг толку подобри резултати имаме во предвидувањето."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLL8ydMhcglW",
        "outputId": "c55c0ed1-675a-46c1-da6f-f6070e659ce5"
      },
      "source": [
        "for k_neighbors in [1,3,7]:\n",
        "  model = KNeighborsClassifier(n_neighbors=k_neighbors)\n",
        "\n",
        "  model.fit(x_train_100,y_train_100)\n",
        "  y_pred_50 = model.predict(x_test_50)\n",
        "  \n",
        "  model.fit(x_train_1000,y_train_1000)\n",
        "  y_pred_300 = model.predict(x_test_300)\n",
        "\n",
        "  model.fit(x_train_10000,y_train_10000)\n",
        "  y_pred_3000 = model.predict(x_test_3000)\n",
        "\n",
        "  print(\"K =\",k_neighbors)\n",
        "  print(classification_report(y_test_50,y_pred_50))\n",
        "  print(classification_report(y_test_300,y_pred_300))\n",
        "  print(classification_report(y_test_3000,y_pred_3000))\n",
        "  print(\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K = 1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.88      0.84        26\n",
            "           1       0.86      0.75      0.80        24\n",
            "\n",
            "    accuracy                           0.82        50\n",
            "   macro avg       0.83      0.82      0.82        50\n",
            "weighted avg       0.82      0.82      0.82        50\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.93      0.93       169\n",
            "           1       0.92      0.92      0.92       131\n",
            "\n",
            "    accuracy                           0.93       300\n",
            "   macro avg       0.93      0.93      0.93       300\n",
            "weighted avg       0.93      0.93      0.93       300\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      1493\n",
            "           1       0.98      0.98      0.98      1507\n",
            "\n",
            "    accuracy                           0.98      3000\n",
            "   macro avg       0.98      0.98      0.98      3000\n",
            "weighted avg       0.98      0.98      0.98      3000\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "K = 3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.77      0.77        26\n",
            "           1       0.75      0.75      0.75        24\n",
            "\n",
            "    accuracy                           0.76        50\n",
            "   macro avg       0.76      0.76      0.76        50\n",
            "weighted avg       0.76      0.76      0.76        50\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.93      0.93       169\n",
            "           1       0.91      0.92      0.92       131\n",
            "\n",
            "    accuracy                           0.93       300\n",
            "   macro avg       0.92      0.93      0.93       300\n",
            "weighted avg       0.93      0.93      0.93       300\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98      1493\n",
            "           1       0.98      0.97      0.98      1507\n",
            "\n",
            "    accuracy                           0.98      3000\n",
            "   macro avg       0.98      0.98      0.98      3000\n",
            "weighted avg       0.98      0.98      0.98      3000\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "K = 7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.69      0.64        26\n",
            "           1       0.60      0.50      0.55        24\n",
            "\n",
            "    accuracy                           0.60        50\n",
            "   macro avg       0.60      0.60      0.59        50\n",
            "weighted avg       0.60      0.60      0.60        50\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.95      0.94       169\n",
            "           1       0.93      0.92      0.93       131\n",
            "\n",
            "    accuracy                           0.94       300\n",
            "   macro avg       0.94      0.94      0.94       300\n",
            "weighted avg       0.94      0.94      0.94       300\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98      1493\n",
            "           1       0.98      0.97      0.98      1507\n",
            "\n",
            "    accuracy                           0.98      3000\n",
            "   macro avg       0.98      0.98      0.98      3000\n",
            "weighted avg       0.98      0.98      0.98      3000\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su2YL5jZvXH4"
      },
      "source": [
        "## Модел со Decision Tree\n",
        "Истото го гледаме и овде.\n",
        "Со тоа што плус овде резултатите остануваат исти дури и кога тренирачкото множество е >1000 примероци. Не прави голема разлика многу критериумот за поделба во комбинација со максималната длабочина на дрвото во однос на резултатите."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXLwWqf_vaBH",
        "outputId": "665d34be-68dd-43be-f7c7-1c5205c8d683"
      },
      "source": [
        "for criteria in ['gini','entropy']:\n",
        "  for depth in [10,100]:\n",
        "    model = DecisionTreeClassifier(criterion=criteria, max_depth=depth,random_state=42)\n",
        "    \n",
        "    model.fit(x_train_100,y_train_100)\n",
        "    y_pred_50 = model.predict(x_test_50)\n",
        "    \n",
        "    model.fit(x_train_1000,y_train_1000)\n",
        "    y_pred_300 = model.predict(x_test_300)\n",
        "\n",
        "    model.fit(x_train_10000,y_train_10000)\n",
        "    y_pred_3000 = model.predict(x_test_3000)\n",
        "\n",
        "    print(\"CRITERION=\",criteria,\"\\tMAX DEPTH=\",depth)\n",
        "    print(classification_report(y_test_50,y_pred_50))\n",
        "    print(classification_report(y_test_300,y_pred_300))\n",
        "    print(classification_report(y_test_3000,y_pred_3000))\n",
        "    print(\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CRITERION= gini \tMAX DEPTH= 10\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.85      0.75        26\n",
            "           1       0.76      0.54      0.63        24\n",
            "\n",
            "    accuracy                           0.70        50\n",
            "   macro avg       0.72      0.69      0.69        50\n",
            "weighted avg       0.71      0.70      0.69        50\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       169\n",
            "           1       0.97      0.98      0.98       131\n",
            "\n",
            "    accuracy                           0.98       300\n",
            "   macro avg       0.98      0.98      0.98       300\n",
            "weighted avg       0.98      0.98      0.98       300\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.88      0.91      1493\n",
            "           1       0.89      0.95      0.92      1507\n",
            "\n",
            "    accuracy                           0.91      3000\n",
            "   macro avg       0.92      0.91      0.91      3000\n",
            "weighted avg       0.92      0.91      0.91      3000\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CRITERION= gini \tMAX DEPTH= 100\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.85      0.75        26\n",
            "           1       0.76      0.54      0.63        24\n",
            "\n",
            "    accuracy                           0.70        50\n",
            "   macro avg       0.72      0.69      0.69        50\n",
            "weighted avg       0.71      0.70      0.69        50\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       169\n",
            "           1       0.97      0.98      0.98       131\n",
            "\n",
            "    accuracy                           0.98       300\n",
            "   macro avg       0.98      0.98      0.98       300\n",
            "weighted avg       0.98      0.98      0.98       300\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1493\n",
            "           1       1.00      1.00      1.00      1507\n",
            "\n",
            "    accuracy                           1.00      3000\n",
            "   macro avg       1.00      1.00      1.00      3000\n",
            "weighted avg       1.00      1.00      1.00      3000\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CRITERION= entropy \tMAX DEPTH= 10\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.77      0.71        26\n",
            "           1       0.70      0.58      0.64        24\n",
            "\n",
            "    accuracy                           0.68        50\n",
            "   macro avg       0.68      0.68      0.68        50\n",
            "weighted avg       0.68      0.68      0.68        50\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.88      0.94       169\n",
            "           1       0.87      1.00      0.93       131\n",
            "\n",
            "    accuracy                           0.93       300\n",
            "   macro avg       0.93      0.94      0.93       300\n",
            "weighted avg       0.94      0.93      0.93       300\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.63      0.63      1493\n",
            "           1       0.63      0.63      0.63      1507\n",
            "\n",
            "    accuracy                           0.63      3000\n",
            "   macro avg       0.63      0.63      0.63      3000\n",
            "weighted avg       0.63      0.63      0.63      3000\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CRITERION= entropy \tMAX DEPTH= 100\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.77      0.71        26\n",
            "           1       0.70      0.58      0.64        24\n",
            "\n",
            "    accuracy                           0.68        50\n",
            "   macro avg       0.68      0.68      0.68        50\n",
            "weighted avg       0.68      0.68      0.68        50\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.95      0.97       169\n",
            "           1       0.94      0.98      0.96       131\n",
            "\n",
            "    accuracy                           0.96       300\n",
            "   macro avg       0.96      0.96      0.96       300\n",
            "weighted avg       0.96      0.96      0.96       300\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1493\n",
            "           1       1.00      1.00      1.00      1507\n",
            "\n",
            "    accuracy                           1.00      3000\n",
            "   macro avg       1.00      1.00      1.00      3000\n",
            "weighted avg       1.00      1.00      1.00      3000\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLpY7EvAHLqx"
      },
      "source": [
        "# В) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CGhilWt7bM4"
      },
      "source": [
        "## Лоадирање на податоците"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOZMWw7z2j3h"
      },
      "source": [
        "dataset = load_iris()\n",
        "X = dataset.data\n",
        "y = dataset.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfN7nZa87jBj"
      },
      "source": [
        "## Модел со KNN класификација\n",
        "[Во една листа се претставени точностите при предвидувањето за секој Fold]\n",
        "\n",
        "За секој Fold гледаме каква е точноста на предвидувањето со KNN, затоа гледаме 10 елементи во листата што е испечатена.\n",
        "\n",
        "За секој параметар гледаме дека некои точности како да си менуваат местата во некои од Fold-овите. Но остануваат истите 0.93, 0.86 и 1.   \n",
        "Од прв поглед, можам да претпоставам дека некои примероци се „проблематични“ што само овие бројки ги перципираме."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkQZqzuq3Nq6",
        "outputId": "f1d43806-6221-4b82-d70d-884101def203"
      },
      "source": [
        "for k_neighbors in [1,3,7]:\n",
        "  model = KNeighborsClassifier(n_neighbors=k_neighbors)\n",
        "  print(\"K =\",k_neighbors)\n",
        "  print(cross_val_score(model,X,y,cv=10,scoring='accuracy'))\n",
        "  print(\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K = 1\n",
            "[1.         0.93333333 1.         0.93333333 0.86666667 1.\n",
            " 0.86666667 1.         1.         1.        ]\n",
            "\n",
            "\n",
            "\n",
            "K = 3\n",
            "[1.         0.93333333 1.         0.93333333 0.86666667 1.\n",
            " 0.93333333 1.         1.         1.        ]\n",
            "\n",
            "\n",
            "\n",
            "K = 7\n",
            "[1.         0.93333333 1.         1.         0.86666667 0.93333333\n",
            " 0.93333333 1.         1.         1.        ]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOifnhKnUokX"
      },
      "source": [
        "## Модел со Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRdIbksHUrJ7",
        "outputId": "2ce8d42e-9cee-4616-9184-d641880d7ed4"
      },
      "source": [
        "for criteria in ['gini','entropy']:\n",
        "  for depth in [10,100]:\n",
        "    model = DecisionTreeClassifier(criterion=criteria, max_depth=depth,random_state=42)\n",
        "\n",
        "    print(\"CRITERION=\",criteria,\"\\tMAX DEPTH=\",depth)\n",
        "    print(cross_val_score(model,X,y,cv=10,scoring='accuracy'))\n",
        "    print(\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CRITERION= gini \tMAX DEPTH= 10\n",
            "[1.         0.93333333 1.         0.93333333 0.93333333 0.86666667\n",
            " 0.93333333 0.93333333 1.         1.        ]\n",
            "\n",
            "\n",
            "\n",
            "CRITERION= gini \tMAX DEPTH= 100\n",
            "[1.         0.93333333 1.         0.93333333 0.93333333 0.86666667\n",
            " 0.93333333 0.93333333 1.         1.        ]\n",
            "\n",
            "\n",
            "\n",
            "CRITERION= entropy \tMAX DEPTH= 10\n",
            "[1.         0.93333333 1.         0.93333333 0.93333333 0.86666667\n",
            " 0.93333333 0.93333333 1.         1.        ]\n",
            "\n",
            "\n",
            "\n",
            "CRITERION= entropy \tMAX DEPTH= 100\n",
            "[1.         0.93333333 1.         0.93333333 0.93333333 0.86666667\n",
            " 0.93333333 0.93333333 1.         1.        ]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p29OgL3HHQ7X"
      },
      "source": [
        "# Г)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCVPDN-ncIIa"
      },
      "source": [
        "## Енкодирање на податоците\n",
        "\n",
        "При вчитувањето на податоците, таргет класата е текстуална, па потребно е енкодирање нејзино."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIeOkcEza86s",
        "outputId": "3c171f3d-5087-48d6-ad13-c68a2d17005a"
      },
      "source": [
        "data = arff.loadarff('seismic-bumps.arff')\n",
        "df = pd.DataFrame(data[0])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>seismic</th>\n",
              "      <th>seismoacoustic</th>\n",
              "      <th>shift</th>\n",
              "      <th>genergy</th>\n",
              "      <th>gpuls</th>\n",
              "      <th>gdenergy</th>\n",
              "      <th>gdpuls</th>\n",
              "      <th>ghazard</th>\n",
              "      <th>nbumps</th>\n",
              "      <th>nbumps2</th>\n",
              "      <th>nbumps3</th>\n",
              "      <th>nbumps4</th>\n",
              "      <th>nbumps5</th>\n",
              "      <th>nbumps6</th>\n",
              "      <th>nbumps7</th>\n",
              "      <th>nbumps89</th>\n",
              "      <th>energy</th>\n",
              "      <th>maxenergy</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b'a'</td>\n",
              "      <td>b'a'</td>\n",
              "      <td>b'N'</td>\n",
              "      <td>15180.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>-72.0</td>\n",
              "      <td>-72.0</td>\n",
              "      <td>b'a'</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>b'0'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>b'a'</td>\n",
              "      <td>b'a'</td>\n",
              "      <td>b'N'</td>\n",
              "      <td>14720.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>-70.0</td>\n",
              "      <td>-79.0</td>\n",
              "      <td>b'a'</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>b'0'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b'a'</td>\n",
              "      <td>b'a'</td>\n",
              "      <td>b'N'</td>\n",
              "      <td>8050.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>-81.0</td>\n",
              "      <td>-78.0</td>\n",
              "      <td>b'a'</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>b'0'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b'a'</td>\n",
              "      <td>b'a'</td>\n",
              "      <td>b'N'</td>\n",
              "      <td>28820.0</td>\n",
              "      <td>171.0</td>\n",
              "      <td>-23.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>b'a'</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3000.0</td>\n",
              "      <td>3000.0</td>\n",
              "      <td>b'0'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b'a'</td>\n",
              "      <td>b'a'</td>\n",
              "      <td>b'N'</td>\n",
              "      <td>12640.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>-63.0</td>\n",
              "      <td>-52.0</td>\n",
              "      <td>b'a'</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>b'0'</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  seismic seismoacoustic shift  genergy  ...  nbumps89  energy  maxenergy class\n",
              "0    b'a'           b'a'  b'N'  15180.0  ...       0.0     0.0        0.0  b'0'\n",
              "1    b'a'           b'a'  b'N'  14720.0  ...       0.0  2000.0     2000.0  b'0'\n",
              "2    b'a'           b'a'  b'N'   8050.0  ...       0.0     0.0        0.0  b'0'\n",
              "3    b'a'           b'a'  b'N'  28820.0  ...       0.0  3000.0     3000.0  b'0'\n",
              "4    b'a'           b'a'  b'N'  12640.0  ...       0.0     0.0        0.0  b'0'\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24lNC7xAbWL8"
      },
      "source": [
        "df = df.apply(LabelEncoder().fit_transform)\n",
        "X = df.drop(columns=['class'],axis=1)\n",
        "y = df['class']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSEPaUCcdMK8"
      },
      "source": [
        "## Модел со KNN класификација\n",
        "\n",
        "Овде најдобриот модел е во случаевите кога K=3,7 во 5-тиот Fold со точност >0.93"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYa8AN1wdI86",
        "outputId": "40b85287-15f4-433d-df26-115a59cef163"
      },
      "source": [
        "for k_neighbors in [1,3,7]:\n",
        "  model = KNeighborsClassifier(n_neighbors=k_neighbors)\n",
        "  print(\"K =\",k_neighbors)\n",
        "  print(cross_val_score(model,X,y,cv=10,scoring='accuracy'))\n",
        "  print(\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K = 1\n",
            "[0.86100386 0.63320463 0.69498069 0.92277992 0.91860465 0.87209302\n",
            " 0.89534884 0.8875969  0.89534884 0.90310078]\n",
            "\n",
            "\n",
            "\n",
            "K = 3\n",
            "[0.86486486 0.73745174 0.77220077 0.93436293 0.93023256 0.93023256\n",
            " 0.90697674 0.93023256 0.92635659 0.92635659]\n",
            "\n",
            "\n",
            "\n",
            "K = 7\n",
            "[0.84555985 0.78764479 0.81467181 0.93436293 0.93410853 0.93410853\n",
            " 0.93410853 0.93410853 0.93410853 0.93410853]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xymMbiEqgnXL"
      },
      "source": [
        "## Модел со Decision Tree\n",
        "\n",
        "Овде е интересното што најдобриот модел од Decision Tree е со параметарот max depth = 10 и без разлика дали критериумот за поделба на дрвото е gini или ентропија"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "na7vg8LSgk5U",
        "outputId": "0064b30d-8e4a-4cf3-944e-c7361e16ce8c"
      },
      "source": [
        "for criteria in ['gini','entropy']:\n",
        "  for depth in [10,100]:\n",
        "    model = DecisionTreeClassifier(criterion=criteria, max_depth=depth,random_state=42)\n",
        "\n",
        "    print(\"CRITERION=\",criteria,\"\\tMAX DEPTH=\",depth)\n",
        "    print(cross_val_score(model,X,y,cv=10,scoring='accuracy'))\n",
        "    print(\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CRITERION= gini \tMAX DEPTH= 10\n",
            "[0.85328185 0.67953668 0.77220077 0.91505792 0.93023256 0.91472868\n",
            " 0.91860465 0.92635659 0.90697674 0.93023256]\n",
            "\n",
            "\n",
            "\n",
            "CRITERION= gini \tMAX DEPTH= 100\n",
            "[0.84942085 0.67181467 0.75289575 0.84942085 0.90310078 0.89147287\n",
            " 0.87209302 0.90697674 0.88372093 0.91860465]\n",
            "\n",
            "\n",
            "\n",
            "CRITERION= entropy \tMAX DEPTH= 10\n",
            "[0.86486486 0.74903475 0.82625483 0.91891892 0.93023256 0.91085271\n",
            " 0.91860465 0.93023256 0.92248062 0.91472868]\n",
            "\n",
            "\n",
            "\n",
            "CRITERION= entropy \tMAX DEPTH= 100\n",
            "[0.86486486 0.69111969 0.77606178 0.91505792 0.8875969  0.86046512\n",
            " 0.91472868 0.8875969  0.89534884 0.89147287]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyLdJ1B9HUpo"
      },
      "source": [
        "# Д)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mG0_ZyCP1-r9"
      },
      "source": [
        "## Креирање на податочното множество и поделбата негова на тренинг и тест множеството\n",
        "\n",
        "Ги читаме податоците од датотека, ги средуваме со цел да добиеме features и таргет класата.\n",
        "Ги енкодираме y вредностите, бидејќи се букви со бројки\n",
        "од 0-25 соодветно со редоследот во латиницата.  \n",
        "На крај го делиме множеството така што големината на тренингот е 2/3, додека пак тестирачкото е 1/3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zYsJl9kc7k0"
      },
      "source": [
        "with open('/content/letter-recognition.data') as f:\n",
        "    lines = f.readlines()\n",
        "dataset = [ line.split() for line in lines ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuFwpqPGvFhI"
      },
      "source": [
        "y = [line[0][0] for line in dataset]\n",
        "X = [list(map(int,line[0].split(\",\")[1:])) for line in dataset]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNc63Vw20O1J"
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(y)\n",
        "y = encoder.transform(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmLndqCC49I0"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=1/3, train_size=2/3, random_state=42 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgK_iJW04Drw"
      },
      "source": [
        "## Модел со KNN класификација\n",
        "\n",
        "Овде се покажа дека KNN е подобро да се искористи, отколку DecisionTree, бидејќи резултатите се значително подобри\n",
        "каде што точноста со KNN e 95%, додека Decision Tree e 88%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3MEXmBI4DN6",
        "outputId": "4e0337e3-106e-4eb2-c8ea-d136cee10ba7"
      },
      "source": [
        "for k_neighbors in [1,3,7]:\n",
        "  model = KNeighborsClassifier(n_neighbors=k_neighbors)\n",
        "  model.fit(x_train,y_train)\n",
        "  y_pred = model.predict(x_test)\n",
        "  print(\"K =\",k_neighbors)\n",
        "  print(classification_report(y_test,y_pred))\n",
        "  print(\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K = 1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       267\n",
            "           1       0.89      0.92      0.90       256\n",
            "           2       0.97      0.95      0.96       214\n",
            "           3       0.94      0.96      0.95       284\n",
            "           4       0.96      0.94      0.95       261\n",
            "           5       0.92      0.95      0.94       235\n",
            "           6       0.95      0.94      0.95       247\n",
            "           7       0.89      0.83      0.86       241\n",
            "           8       0.95      0.95      0.95       244\n",
            "           9       0.95      0.94      0.94       248\n",
            "          10       0.87      0.93      0.90       204\n",
            "          11       0.98      0.98      0.98       249\n",
            "          12       1.00      0.98      0.99       276\n",
            "          13       0.97      0.94      0.96       262\n",
            "          14       0.93      0.96      0.94       251\n",
            "          15       0.96      0.93      0.95       280\n",
            "          16       0.96      0.95      0.95       281\n",
            "          17       0.89      0.93      0.91       256\n",
            "          18       0.98      0.97      0.98       255\n",
            "          19       0.96      0.97      0.97       260\n",
            "          20       0.99      0.99      0.99       299\n",
            "          21       0.94      0.97      0.96       269\n",
            "          22       0.97      1.00      0.99       240\n",
            "          23       0.97      0.93      0.95       275\n",
            "          24       0.97      0.97      0.97       273\n",
            "          25       0.97      0.98      0.98       240\n",
            "\n",
            "    accuracy                           0.95      6667\n",
            "   macro avg       0.95      0.95      0.95      6667\n",
            "weighted avg       0.95      0.95      0.95      6667\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "K = 3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       267\n",
            "           1       0.84      0.95      0.89       256\n",
            "           2       0.94      0.95      0.94       214\n",
            "           3       0.89      0.97      0.93       284\n",
            "           4       0.93      0.95      0.94       261\n",
            "           5       0.90      0.93      0.92       235\n",
            "           6       0.95      0.93      0.94       247\n",
            "           7       0.89      0.80      0.84       241\n",
            "           8       0.95      0.95      0.95       244\n",
            "           9       0.97      0.94      0.95       248\n",
            "          10       0.88      0.91      0.89       204\n",
            "          11       0.99      0.97      0.98       249\n",
            "          12       0.98      0.99      0.99       276\n",
            "          13       0.98      0.94      0.96       262\n",
            "          14       0.92      0.96      0.94       251\n",
            "          15       0.97      0.91      0.94       280\n",
            "          16       0.96      0.94      0.95       281\n",
            "          17       0.90      0.90      0.90       256\n",
            "          18       0.99      0.95      0.97       255\n",
            "          19       0.94      0.96      0.95       260\n",
            "          20       1.00      0.96      0.98       299\n",
            "          21       0.97      0.96      0.96       269\n",
            "          22       0.99      0.99      0.99       240\n",
            "          23       0.97      0.94      0.96       275\n",
            "          24       0.97      0.96      0.97       273\n",
            "          25       0.99      0.98      0.98       240\n",
            "\n",
            "    accuracy                           0.95      6667\n",
            "   macro avg       0.95      0.95      0.95      6667\n",
            "weighted avg       0.95      0.95      0.95      6667\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "K = 7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       267\n",
            "           1       0.85      0.95      0.89       256\n",
            "           2       0.97      0.95      0.96       214\n",
            "           3       0.87      0.97      0.92       284\n",
            "           4       0.95      0.94      0.94       261\n",
            "           5       0.90      0.94      0.92       235\n",
            "           6       0.94      0.94      0.94       247\n",
            "           7       0.91      0.79      0.85       241\n",
            "           8       0.94      0.95      0.95       244\n",
            "           9       0.97      0.91      0.94       248\n",
            "          10       0.87      0.94      0.90       204\n",
            "          11       0.98      0.96      0.97       249\n",
            "          12       0.99      0.98      0.99       276\n",
            "          13       0.97      0.93      0.95       262\n",
            "          14       0.90      0.96      0.93       251\n",
            "          15       0.98      0.91      0.95       280\n",
            "          16       0.96      0.96      0.96       281\n",
            "          17       0.90      0.91      0.91       256\n",
            "          18       0.98      0.93      0.96       255\n",
            "          19       0.95      0.95      0.95       260\n",
            "          20       0.98      0.96      0.97       299\n",
            "          21       0.96      0.96      0.96       269\n",
            "          22       0.99      0.98      0.98       240\n",
            "          23       0.97      0.95      0.96       275\n",
            "          24       0.97      0.97      0.97       273\n",
            "          25       0.98      0.97      0.98       240\n",
            "\n",
            "    accuracy                           0.95      6667\n",
            "   macro avg       0.95      0.94      0.94      6667\n",
            "weighted avg       0.95      0.95      0.95      6667\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0EJLSUH5-kP"
      },
      "source": [
        "## Модел со Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-TiT83p5yy9",
        "outputId": "9a5fa4d5-2f73-4455-dffd-126f5d51f4bb"
      },
      "source": [
        "for criteria in ['gini','entropy']:\n",
        "  for depth in [10,100]:\n",
        "    model = DecisionTreeClassifier(criterion=criteria, max_depth=depth,random_state=42)\n",
        "    model.fit(x_train, y_train)\n",
        "    y_pred = model.predict(x_test)\n",
        "    print(\"CRITERION=\",criteria,\"\\tMAX DEPTH=\",depth)\n",
        "    print(classification_report(y_test,y_pred))\n",
        "    print(\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CRITERION= gini \tMAX DEPTH= 10\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.82      0.89       267\n",
            "           1       0.63      0.65      0.64       256\n",
            "           2       0.35      0.77      0.48       214\n",
            "           3       0.59      0.79      0.68       284\n",
            "           4       0.75      0.55      0.64       261\n",
            "           5       0.72      0.71      0.72       235\n",
            "           6       0.43      0.73      0.54       247\n",
            "           7       0.34      0.32      0.33       241\n",
            "           8       0.87      0.81      0.84       244\n",
            "           9       0.98      0.76      0.86       248\n",
            "          10       0.57      0.70      0.63       204\n",
            "          11       0.92      0.78      0.84       249\n",
            "          12       0.92      0.83      0.87       276\n",
            "          13       0.89      0.79      0.84       262\n",
            "          14       0.57      0.62      0.59       251\n",
            "          15       0.62      0.80      0.70       280\n",
            "          16       0.54      0.65      0.59       281\n",
            "          17       0.73      0.55      0.63       256\n",
            "          18       0.74      0.60      0.66       255\n",
            "          19       0.92      0.75      0.83       260\n",
            "          20       0.94      0.78      0.85       299\n",
            "          21       0.96      0.85      0.90       269\n",
            "          22       0.96      0.84      0.90       240\n",
            "          23       0.92      0.56      0.69       275\n",
            "          24       0.87      0.77      0.82       273\n",
            "          25       0.91      0.74      0.82       240\n",
            "\n",
            "    accuracy                           0.71      6667\n",
            "   macro avg       0.75      0.71      0.72      6667\n",
            "weighted avg       0.76      0.71      0.73      6667\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CRITERION= gini \tMAX DEPTH= 100\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.93      0.94       267\n",
            "           1       0.81      0.81      0.81       256\n",
            "           2       0.93      0.86      0.90       214\n",
            "           3       0.80      0.88      0.84       284\n",
            "           4       0.81      0.93      0.86       261\n",
            "           5       0.84      0.85      0.84       235\n",
            "           6       0.81      0.84      0.82       247\n",
            "           7       0.76      0.74      0.75       241\n",
            "           8       0.85      0.87      0.86       244\n",
            "           9       0.89      0.87      0.88       248\n",
            "          10       0.82      0.84      0.83       204\n",
            "          11       0.92      0.92      0.92       249\n",
            "          12       0.90      0.92      0.91       276\n",
            "          13       0.91      0.87      0.89       262\n",
            "          14       0.83      0.82      0.82       251\n",
            "          15       0.86      0.89      0.88       280\n",
            "          16       0.84      0.81      0.82       281\n",
            "          17       0.83      0.80      0.81       256\n",
            "          18       0.83      0.86      0.85       255\n",
            "          19       0.90      0.88      0.89       260\n",
            "          20       0.90      0.90      0.90       299\n",
            "          21       0.92      0.91      0.92       269\n",
            "          22       0.93      0.95      0.94       240\n",
            "          23       0.89      0.86      0.88       275\n",
            "          24       0.90      0.88      0.89       273\n",
            "          25       0.93      0.84      0.88       240\n",
            "\n",
            "    accuracy                           0.87      6667\n",
            "   macro avg       0.87      0.87      0.87      6667\n",
            "weighted avg       0.87      0.87      0.87      6667\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CRITERION= entropy \tMAX DEPTH= 10\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.95      0.96       267\n",
            "           1       0.70      0.71      0.70       256\n",
            "           2       0.89      0.72      0.80       214\n",
            "           3       0.76      0.84      0.80       284\n",
            "           4       0.71      0.81      0.76       261\n",
            "           5       0.70      0.77      0.74       235\n",
            "           6       0.80      0.74      0.77       247\n",
            "           7       0.57      0.71      0.63       241\n",
            "           8       0.95      0.82      0.88       244\n",
            "           9       0.93      0.85      0.89       248\n",
            "          10       0.80      0.59      0.68       204\n",
            "          11       0.88      0.88      0.88       249\n",
            "          12       0.89      0.91      0.90       276\n",
            "          13       0.91      0.87      0.89       262\n",
            "          14       0.77      0.78      0.78       251\n",
            "          15       0.87      0.76      0.82       280\n",
            "          16       0.80      0.78      0.79       281\n",
            "          17       0.61      0.79      0.68       256\n",
            "          18       0.80      0.73      0.76       255\n",
            "          19       0.84      0.84      0.84       260\n",
            "          20       0.88      0.89      0.89       299\n",
            "          21       0.94      0.91      0.92       269\n",
            "          22       0.85      0.92      0.88       240\n",
            "          23       0.82      0.77      0.79       275\n",
            "          24       0.89      0.86      0.87       273\n",
            "          25       0.80      0.89      0.84       240\n",
            "\n",
            "    accuracy                           0.81      6667\n",
            "   macro avg       0.82      0.81      0.81      6667\n",
            "weighted avg       0.82      0.81      0.82      6667\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CRITERION= entropy \tMAX DEPTH= 100\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97       267\n",
            "           1       0.81      0.82      0.81       256\n",
            "           2       0.88      0.82      0.85       214\n",
            "           3       0.84      0.87      0.86       284\n",
            "           4       0.85      0.86      0.85       261\n",
            "           5       0.76      0.82      0.79       235\n",
            "           6       0.83      0.86      0.84       247\n",
            "           7       0.81      0.76      0.78       241\n",
            "           8       0.91      0.87      0.89       244\n",
            "           9       0.92      0.87      0.89       248\n",
            "          10       0.82      0.88      0.85       204\n",
            "          11       0.92      0.93      0.92       249\n",
            "          12       0.98      0.94      0.96       276\n",
            "          13       0.95      0.89      0.92       262\n",
            "          14       0.81      0.88      0.84       251\n",
            "          15       0.87      0.85      0.86       280\n",
            "          16       0.88      0.85      0.86       281\n",
            "          17       0.81      0.82      0.82       256\n",
            "          18       0.82      0.88      0.85       255\n",
            "          19       0.92      0.88      0.90       260\n",
            "          20       0.92      0.91      0.92       299\n",
            "          21       0.92      0.91      0.92       269\n",
            "          22       0.96      0.94      0.95       240\n",
            "          23       0.89      0.89      0.89       275\n",
            "          24       0.92      0.89      0.90       273\n",
            "          25       0.89      0.92      0.91       240\n",
            "\n",
            "    accuracy                           0.88      6667\n",
            "   macro avg       0.88      0.88      0.88      6667\n",
            "weighted avg       0.88      0.88      0.88      6667\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8Q9tI_n6bpV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}